{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "train_data_path = 'chat_gpt_context/distilbert_squad_dataset.json'\n",
    "\n",
    "# JSON 파일 불러오기\n",
    "# with open(train_data_path) as f:\n",
    "#   train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertForQuestionAnswering, DistilBertTokenizerFast, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQuAD 데이터셋을 불러오는 함수\n",
    "def load_squad_data(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        squad_data = json.load(f)[\"data\"]\n",
    "    return squad_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum split size to avoid memory fragmentation\n",
    "torch.backends.cuda.max_split_size_bytes = 128 * 1024 * 1024  # 128 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQuAD 데이터셋과 DistilBERT의 tokenizer, 모델을 불러옴\n",
    "squad_data = load_squad_data(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n",
    "gpu_model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\", \n",
    "                                   max_length = 1024, max_position_embeddings = 1024, ignore_mismatched_sizes = True\n",
    "                                   ).to(device)\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\", max_length = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_question = \"\"\"\n",
    "GET /admin/exec.php3?cmd=dir%20c:\\\\ HTTP/1.1¶Connection: Keep-Alive¶Content-Type: application/x-www-form-urlencoded¶Content-Length: 12¶Host: 10.10.123.123¶User-Agent: Mozilla/5.00 (Nikto/2.1.6) (Evasions:None) (Test:003219)¶¶dump_sql=foo In the case of the corresponding payload, please write in one sentence or less, which type it corresponds to.\n",
    "\"\"\"\n",
    "\n",
    "context = \"\"\"\n",
    "If any string appears between select and from or between case and when in payload, it is a type of SQLInjection.¶If any string appears between jndi and dap or between jndi and dns in payload, it is a type of JNDIInjection.¶If any string appears between script and alert in payload, it is a type of CrossSiteScripting.¶If any string appears between rm and rf or between wget and ttp or between chmod and 777 or between cd and tmp before HTTP/1. in payload, it is a type of CommandInjection.¶If any string appears user and agent before zgrab or nmap or dirbuster or ahrefsbot or baiduspider or mj12bot or petalbot or semrushbot or curl/ or masscan or sqlmap or urlgrabber in payload, it is a type of maliciousbot.¶If any string appears wp-login or wp-context or wp-include or wp-config in payload, it is a type of WordPress.¶If any string appears between etc and passwd or between cgi and bin or between cmd and open or between echo and shellshock or between php and echo or between admin and php or between setup and php in payload, it is a type of AttemptAccessAdminPage.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(new_question))\n",
    "print(len(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "answering = pipeline('question-answering', model = cpu_model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = answering(question = new_question, context = context)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQuAD 데이터셋을 DistilBERT의 입력 형식에 맞게 변환하는 함수\n",
    "def convert_squad_data_to_features(squad_data, tokenizer, max_seq_length):\n",
    "    features = []\n",
    "    for article in squad_data:\n",
    "        for paragraph in article[\"paragraphs\"]:\n",
    "            context = paragraph[\"context\"]\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                qas_id = qa[\"id\"]\n",
    "                print(qas_id)\n",
    "                question = qa[\"question\"]\n",
    "                print(question)\n",
    "                answer_text = qa[\"answers\"][0][\"text\"]\n",
    "                print(answer_text)\n",
    "                start_position = qa[\"answers\"][0][\"answer_start\"]\n",
    "                print(start_position)\n",
    "                end_position = start_position + len(answer_text)\n",
    "                print(end_position)\n",
    "\n",
    "                # context와 question을 DistilBERT의 입력 형식에 맞게 tokenize\n",
    "                encoded_dict = tokenizer(question, context, max_length=max_seq_length, padding=\"max_length\",\n",
    "                                         # 지정된 token 수 (예, 1024개) 초과 시, 자름\n",
    "                                         truncation=True, return_offsets_mapping=True, return_token_type_ids = True)\n",
    "                print(encoded_dict)\n",
    "                # answer의 시작 위치와 끝 위치를 토큰 단위로 변환\n",
    "                token_start_position = 0\n",
    "                token_end_position = 0\n",
    "                for i, offset in enumerate(encoded_dict[\"offset_mapping\"]):\n",
    "                    if offset[0] <= start_position and offset[1] > start_position:\n",
    "                        token_start_position = i\n",
    "                    if offset[0] < end_position and offset[1] >= end_position:\n",
    "                        token_end_position = i\n",
    "\n",
    "                # feature 추가\n",
    "                input_ids = encoded_dict[\"input_ids\"]\n",
    "                attention_mask = encoded_dict[\"attention_mask\"]\n",
    "                # token_type_ids = encoded_dict.token_type_ids()\n",
    "                token_type_ids = encoded_dict['token_type_ids']\n",
    "\n",
    "                features.append((input_ids, attention_mask, token_type_ids, token_start_position, token_end_position))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ips_query = \"\"\"\n",
    "\n",
    "    SELECT\n",
    "\n",
    "        IF(INT(RLIKE(payload, 'VCAvY2dpLWJpbi9waHA0') )>0\n",
    "        OR INT(RLIKE(payload, 'L2NnaS1iaW4v') )>0\n",
    "        OR INT(RLIKE(payload, 'IC9jZ2ktYmlu') )>0\n",
    "        OR INT(RLIKE(payload, 'UE9TVCAvY2dpLWJpbi9waHA/') )>0\n",
    "        OR INT(RLIKE(payload, 'VCAvY2dpLWJpbi9w') )>0\n",
    "        OR INT(RLIKE(payload, 'ZGllKEBtZDU=') )>0\n",
    "        OR INT(RLIKE(payload, 'L2FueWZvcm0yL3VwZGF0ZS9hbnlmb3JtMi5pbmk=') )>0\n",
    "        OR INT(RLIKE(payload, 'Ly5iYXNoX2hpc3Rvcnk=') )>0\n",
    "        OR INT(RLIKE(payload, 'L2V0Yy9wYXNzd2Q=') )>0\n",
    "        OR INT(RLIKE(payload, 'QUFBQUFBQUFBQQ==') )>0\n",
    "        OR INT(RLIKE(payload, 'IG1hc3NjYW4vMS4w') )>0\n",
    "        OR INT(RLIKE(payload, 'd2dldA==') )>0\n",
    "        OR INT(RLIKE(payload, 'MjB3YWl0Zm9yJTIwZGVsYXklMjAn') )>0\n",
    "        OR INT(RLIKE(payload, 'V0FJVEZPUiBERUxBWQ==') )>0\n",
    "        OR INT(RLIKE(payload, 'ZXhlYw==') )>0\n",
    "        OR INT(RLIKE(payload, 'Tm9uZQ==') )>0\n",
    "        OR INT(RLIKE(payload, 'OyB3Z2V0') )>0\n",
    "        OR INT(RLIKE(payload, 'VXNlci1BZ2VudDogRGlyQnVzdGVy') )>0\n",
    "        OR INT(RLIKE(payload, 'cGhwIGRpZShAbWQ1') )>0\n",
    "        OR INT(RLIKE(payload, 'JTI4U0VMRUNUJTIw') )>0\n",
    "                ,1, 0) AS ips_00001_payload_base64,\n",
    "\n",
    "        IF(INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'select(.*?)from') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'select(.*?)count') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'select(.*?)distinct') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'union(.*?)select') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'select(.*?)extractvalue(.*?)xmltype') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'from(.*?)generate(.*?)series') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'from(.*?)group(.*?)by') )>0\n",
    "                ,1, 0) AS ips_00001_payload_sql_comb_01,\n",
    "\n",
    "        IF(INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'case(.*?)when') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'then(.*?)else') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'like') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'sleep') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'delete') )>0\n",
    "                ,1, 0) AS ips_00001_payload_sql_comb_02,\n",
    "\n",
    "        IF(INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'waitfor(.*?)delay') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'db(.*?)sql(.*?)server') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'cast(.*?)chr') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'upper(.*?)xmltype') )>0\n",
    "                ,1, 0) AS ips_00001_payload_sql_comb_03,\n",
    "\n",
    "        IF(INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'script(.*?)alert') )>0\n",
    "        OR INT(RLIKE(LOWER(payload), 'eval') )>0\n",
    "                ,1, 0) AS ips_00001_payload_xss_comb_01,\n",
    "\n",
    "        IF(INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'wget(.*?)ttp') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'chmod(.*?)777') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'rm(.*?)rf') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[0],  'cd(.*?)tmp') )>0\n",
    "                ,1, 0) AS ips_00001_payload_cmd_comb_01,\n",
    "\n",
    "        IF(INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'jndi(.*?)dap') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '),'jndi(.*?)dns') )>0\n",
    "                ,1, 0) AS ips_00001_payload_log4j_comb_01,\n",
    "\n",
    "        IF(INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'etc(.*?)passwd') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'document(.*?)createelement') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'cgi(.*?)bin') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'document(.*?)forms') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'document(.*?)location') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'fckeditor(.*?)filemanager') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'manager(.*?)html') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'current_config(.*?)passwd') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'currentsetting(.*?)htm') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'well(.*?)known') )>0\n",
    "                ,1, 0) AS ips_00001_payload_word_comb_01,\n",
    "\n",
    "        IF(INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'bash(.*?)history') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'apache(.*?)struts') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'document(.*?)open') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'backup(.*?)sql') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'robots(.*?)txt') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'sqlexec(.*?)php') )>0\n",
    "        OR INT(RLIKE(LOWER(payload), 'htaccess') )>0\n",
    "        OR INT(RLIKE(LOWER(payload), 'htpasswd') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'cgi(.*?)cgi') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'api(.*?)ping') )>0\n",
    "                ,1, 0) AS ips_00001_payload_word_comb_02,\n",
    "\n",
    "        IF(INT(RLIKE(LOWER(payload), 'aaaaaaaaaa') )>0\n",
    "        OR INT(RLIKE(LOWER(payload), 'cacacacaca') )>0\n",
    "        OR INT(RLIKE(LOWER(payload), 'mozi[\\\\.]') )>0\n",
    "        OR INT(RLIKE(LOWER(payload), 'bingbot') )>0\n",
    "        OR INT(RLIKE(LOWER(payload), 'md5') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'count(.*?)cgi(.*?)http') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'this(.*?)program(.*?)can') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'get(.*?)ping') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'msadc(.*?)dll(.*?)http') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'filename(.*?)asp') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'filename(.*?)jsp') )>0\n",
    "        OR INT(RLIKE(LOWER(payload), 'powershell'))>0\n",
    "        OR INT(RLIKE(LOWER(payload), '[\\\\.]env'))>0\n",
    "                ,1, 0) AS ips_00001_payload_word_comb_03,\n",
    "\n",
    "        IF(INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'wp-login') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'wp-content') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'wp-include') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'wp-config') )>0\n",
    "                ,1, 0) AS ips_00001_payload_wp_comb_01,\n",
    "\n",
    "        IF(INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'cmd(.*?)open') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'echo(.*?)shellshock') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'php(.*?)echo') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'admin(.*?)php') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'script(.*?)setup(.*?)php') )>0\n",
    "        OR INT(RLIKE(LOWER(payload), 'phpinfo') )>0\n",
    "        OR INT(RLIKE(LOWER(payload), 'administrator') )>0\n",
    "        OR INT(RLIKE(LOWER(payload), 'phpmyadmin') )>0\n",
    "        OR INT(RLIKE(LOWER(payload), 'access') )>0\n",
    "        OR INT(RLIKE(LOWER(payload), 'mdb') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'wise(.*?)survey(.*?)admin') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'admin(.*?)serv(.*?)admpw') )>0\n",
    "        OR INT(RLIKE(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'php(.*?)create(.*?)function') )>0\n",
    "                ,1, 0) AS ips_00001_payload_word_comb_04,\n",
    "\n",
    "        IF(INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[1],  'user(.*?)agent(.*?)zgrab') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[1],  'user(.*?)agent(.*?)nmap') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[1],  'user(.*?)agent(.*?)dirbuster') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[1],  'user(.*?)agent(.*?)ahrefsbot') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[1],  'user(.*?)agent(.*?)baiduspider') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[1],  'user(.*?)agent(.*?)mj12bot') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[1],  'user(.*?)agent(.*?)petalbot') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[1],  'user(.*?)agent(.*?)curl/') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[1],  'user(.*?)agent(.*?)semrushbot') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[1],  'user(.*?)agent(.*?)masscan') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[1],  'user(.*?)agent(.*?)sqlmap') )>0\n",
    "        OR INT(RLIKE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'http/1.', 2)[1],  'user(.*?)agent(.*?)urlgrabber(.*?)yum') )>0\n",
    "                ,1, 0) AS ips_00001_payload_useragent_comb,\n",
    "\n",
    "        (SIZE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'get(.*?)http/1.')) -1)\n",
    "            + (SIZE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'post(.*?)http/1.')) -1)\n",
    "        + (SIZE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'head(.*?)http/1.')) -1)\n",
    "        + (SIZE(SPLIT(REGEXP_REPLACE(LOWER(payload), '\\\\n|\\\\r|\\\\t', ' '), 'option(.*?)http/1.')) -1)\n",
    "        AS ips_00001_payload_whitelist\n",
    "    FROM table\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# new_sql_query의 ips_00001_payload_base64 부터 ips_00001_payload_useragent_comb 까지 추출\n",
    "# re.S의 경우, 줄바꿈 문자열 까지 매치 !!!!!!!\n",
    "attack_query = re.findall(r'ips_00001_payload_base64.*?ips_00001_payload_useragent_comb', ips_query, re.S)[0]\n",
    "# attack_new_sql_query '\\\\n|\\\\r|\\\\t', 'http/1.', 2 는 제거, 단 regex = False\n",
    "attack_query = attack_query.replace('\\\\n|\\\\r|\\\\t', '').replace(\"'http/1.', 2\", '')\n",
    "# new_sql_query의 '' 안에 있는 문자열들을 추출하여 리스트 생성,\n",
    "ai_field = re.findall(r'\\'(.*?)\\'', attack_query)\n",
    "# ai_field에서 'remove_string' 는 제거\n",
    "ai_field = [x for x in ai_field if x != '' and x != ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_list에 element 안에 '(.*?)'가 포함되어 있는 경우, '(.*?)' 기준으로 split 후, 리스트에 추가\n",
    "first_ai_list = [x.split('(.*?)')[0] for x in ai_field if '(.*?)' in x]\n",
    "end_ai_list = [x.split('(.*?)')[1] for x in ai_field if '(.*?)' in x]\n",
    "except_ai_list = [x.replace('[\\\\.]', '.') for x in ai_field]\n",
    "\n",
    "# ai_list의 element 안에 ('*?)' 가 2번 포함되어 있는 경우, 2번째 '(.*?)' 기준으로 split 후, 리스트에 추가\n",
    "two_ai_list = [x.split('(.*?)')[2] for x in ai_field if x.count('(.*?)') == 2]\n",
    "\n",
    "# ai_list의 element 안에 ('*?)' 가 3번 포함되어 있는 경우, 3번째 '(.*?)' 기준으로 split 후, 리스트에 추가\n",
    "three_ai_list = [x.split('(.*?)')[3] for x in ai_field if x.count('(.*?)') == 3]\n",
    "\n",
    "ai_list_split = first_ai_list + end_ai_list + ai_field + except_ai_list + two_ai_list + three_ai_list\n",
    "\n",
    "# ai_list_split 안에 중복되는 element 가 있는 경우, 단일 처리\n",
    "ai_list_split = list(set(ai_list_split))\n",
    "\n",
    "# ai_list_split 안에 '(.*?' 나, '[\\\\.]' 가 포함되어 있는 경우, 제거\n",
    "ai_list_split = [x for x in ai_list_split if '(.*?)' not in x]\n",
    "ai_list_split = [x for x in ai_list_split if '[\\\\.]' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ai_list_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_list_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('chat_gpt_context/distilbert_squad_dataset.csv')\n",
    "answer_list = df['answer'].str.lower().unique()\n",
    "answer_list = list(answer_list)\n",
    "answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ai_list_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(answer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_list = ai_list_split + answer_list\n",
    "ai_list = list(set(ai_list))\n",
    "len(ai_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokens = set(ai_list) - set(tokenizer.vocab.keys())\n",
    "len(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the tokens to the tokenizer vocabulary\n",
    "tokenizer.add_tokens(list(new_tokens))\n",
    "# tokenizer.add_special_tokens({\"additional_special_tokens\": ai_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new, random embeddings for the new tokens\n",
    "gpu_model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 sequence의 최대 길이\n",
    "max_seq_length = 1024\n",
    "\n",
    "# 데이터셋을 feature로 변환\n",
    "features = convert_squad_data_to_features(squad_data, tokenizer, max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_model.config.max_length = max_seq_length\n",
    "# gpu_model.config.max_position_embeddings = 1024\n",
    "gpu_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature를 torch tensor로 변환\n",
    "input_ids = torch.tensor([f[0] for f in features], dtype=torch.long)\n",
    "attention_mask = torch.tensor([f[1] for f in features], dtype=torch.long)\n",
    "token_type_ids = torch.tensor([f[2] for f in features], dtype=torch.long)\n",
    "start_positions = torch.tensor([f[3] for f in features], dtype=torch.long)\n",
    "end_positions = torch.tensor([f[4] for f in features], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # batch: [(input_ids, attention_masks, token_type_ids, start_positions, end_positions), ...]\n",
    "    input_ids = torch.tensor([item[0] for item in batch])\n",
    "    attention_masks = torch.tensor([item[1] for item in batch])\n",
    "    token_type_ids = torch.tensor([item[2] for item in batch])\n",
    "    start_positions = torch.tensor([item[3] for item in batch])\n",
    "    end_positions = torch.tensor([item[4] for item in batch])\n",
    "    return input_ids, attention_masks, token_type_ids, start_positions, end_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer와 learning rate 설정\n",
    "optimizer = AdamW(gpu_model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 2\n",
    "train_dataloader = DataLoader(features, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.to(device)\n",
    "gpu_model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# train loop 설정\n",
    "train_loss = []\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        # 데이터 준비\n",
    "        inputs = {\n",
    "            \"input_ids\": batch[0].to(device),\n",
    "            \"attention_mask\": batch[1].to(device),\n",
    "            # \"token_type_ids\": batch[2].to(device),\n",
    "            \"start_positions\": batch[3].to(device),\n",
    "            \"end_positions\": batch[4].to(device)\n",
    "        }\n",
    "\n",
    "        # forward 수행\n",
    "        gpu_model.train()\n",
    "        outputs = gpu_model(**inputs)\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # backward 수행\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # loss 계산\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    train_loss.append(epoch_loss / len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 데이터셋 로딩\n",
    "eval_features = convert_squad_data_to_features(squad_data, tokenizer, max_seq_length)\n",
    "eval_dataloader = DataLoader(eval_features, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "gpu_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loss = 0\n",
    "for batch in eval_dataloader:\n",
    "    with torch.no_grad():\n",
    "        inputs = {\n",
    "            \"input_ids\": batch[0].to(device),\n",
    "            \"attention_mask\": batch[1].to(device),\n",
    "            \"start_positions\": batch[3].to(device),\n",
    "            \"end_positions\": batch[4].to(device)\n",
    "        }\n",
    "        outputs = gpu_model(**inputs)\n",
    "        # print('@@@@@@@@@@@@')\n",
    "        # print(outputs)\n",
    "        start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
    "        start_positions, end_positions = inputs[\"start_positions\"], inputs[\"end_positions\"]\n",
    "        # batch_loss = loss_fn(start_logits, end_logits, start_positions, end_positions)\n",
    "        batch_loss = loss_fn(start_logits, start_positions) + loss_fn(end_logits, end_positions)\n",
    "\n",
    "        eval_loss += batch_loss.item()\n",
    "\n",
    "eval_loss /= len(eval_dataloader)\n",
    "print(\"Eval Loss:\", eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_question = \"\"\"\n",
    "GET /admin/exec.php3?cmd=dir%20c:\\\\ HTTP/1.1¶Connection: Keep-Alive¶Content-Type: application/x-www-form-urlencoded¶Content-Length: 12¶Host: 10.10.123.123¶User-Agent: Mozilla/5.00 (Nikto/2.1.6) (Evasions:None) (Test:003219)¶¶dump_sql=foo In the case of the corresponding payload, please write in one sentence or less, which type it corresponds to.\n",
    "\"\"\"\n",
    "\n",
    "context = \"\"\"\n",
    "If any string appears between select and from or between case and when in payload, it is a type of SQLInjection.¶If any string appears between jndi and dap or between jndi and dns in payload, it is a type of JNDIInjection.¶If any string appears between script and alert in payload, it is a type of CrossSiteScripting.¶If any string appears between rm and rf or between wget and ttp or between chmod and 777 or between cd and tmp before HTTP/1. in payload, it is a type of CommandInjection.¶If any string appears user and agent before zgrab or nmap or dirbuster or ahrefsbot or baiduspider or mj12bot or petalbot or semrushbot or curl/ or masscan or sqlmap or urlgrabber in payload, it is a type of maliciousbot.¶If any string appears wp-login or wp-context or wp-include or wp-config in payload, it is a type of WordPress.¶If any string appears between etc and passwd or between cgi and bin or between cmd and open or between echo and shellshock or between php and echo or between admin and php or between setup and php in payload, it is a type of AttemptAccessAdminPage.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_index = 0 # index of the GPU device you want to use\n",
    "device = torch.device('cuda', device_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hugging face의 transformers 이용\n",
    "answering = pipeline('question-answering', model = gpu_model, tokenizer = tokenizer, device = device)\n",
    "result = answering(question = new_question, context = context)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch 이용\n",
    "inputs = tokenizer(new_question, context, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = gpu_model(**inputs)\n",
    "\n",
    "answer_start_index = torch.argmax(outputs.start_logits)\n",
    "answer_end_index = torch.argmax(outputs.end_logits)\n",
    "\n",
    "predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "tokenizer.decode(predict_answer_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
